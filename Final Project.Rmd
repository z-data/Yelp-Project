---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
# Load the package required
library("jsonlite")
library(tibble)
library(yelpr)
library(dplyr)

# Get my API key
key = readLines("Yelp API.txt", warn = F)


#I tried a few times and it seems borough by borough is best 
#Manhattan restaurant calls 
resturants = data.frame()
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Manhattan',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Brooklyn restaurant calls 
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Brooklyn',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Queens restaurant calls 
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Queens',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Bronx restaurant calls
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Bronx',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}

dim(resturants)
unique(resturants$businesses.location$city)
head(resturants)

cor(resturants$businesses.rating, resturants$businesses.review_count)
```


```{r}
table(resturants$businesses.is_closed, useNA = "ifany")
```
LG: This is a problem - can we accurately conclude that NA fields are restaurants that have closed? 

```{r}
hist(resturants$businesses.rating,xlab = "ratings out of 5", main = "Histogram of business ratings")
```
```{r}
table(resturants$businesses.price, useNA = "ifany")
```

```{r}
barplot(height = table(resturants$businesses.price,  useNA = "ifany"), 
        names.arg = names(table(resturants$businesses.price, useNA = "ifany")))
```
```{r}
hist(resturants$businesses.review_count, xlab = "Number of reviews", main = "Histogram of review Dist")
```

Methods just to get mine imported too
```{r}
#yelp_biz = jsonlite::stream_in(file( "/Users/zacmacintyre/Desktop/Git Folder/yelp_dataset/yelp_academic_dataset_business.json"))
#yelp_flat = jsonlite::flatten(yelp_biz)
#yelp_tbl = as_tibble(yelp_flat)
# However, most of this data is from BC, CO, FL, GA, MA, OH, OR, and TX (Not NY)
#table(yelp_tbl$state)
# It is a very large dataset
#dim(yelp_tbl)
#names(yelp_tbl)
#Include more than restaurants 
#yelp_tbl %>% mutate(categories = as.character(categories)) %>% select(categories)

#COVID_data = jsonlite::stream_in(file("/Users/zacmacintyre/Desktop/Git Folder/covid_19_dataset_2020_06_10/yelp_academic_dataset_covid_features.json"))
#covid_flat = jsonlite::flatten(COVID_data)
#covid_yelp_tbl = as_tibble(covid_flat)
```

Yelp Dataset for Academic purposed as of March 2020


```{r}
yelp_biz = jsonlite::stream_in(file( "/Users/lukasgeiger/Desktop/Columbia/SeniorYear/Spring2021/AppliedDataMining/FinalProject/yelp_dataset/yelp_academic_dataset_business.json"))
yelp_flat = jsonlite::flatten(yelp_biz)
yelp_tbl = as_tibble(yelp_flat)
# However, most of this data is from BC, CO, FL, GA, MA, OH, OR, and TX (Not NY)
table(yelp_tbl$state)
# It is a very large dataset
dim(yelp_tbl)
names(yelp_tbl)
#Include more than restaurants 
yelp_tbl %>% mutate(categories = as.character(categories)) %>% select(categories)
```

```{r}
COVID_data = jsonlite::stream_in(file( "/Users/lukasgeiger/Desktop/Columbia/SeniorYear/Spring2021/AppliedDataMining/FinalProject/covid_19_dataset_2020_06_10/yelp_academic_dataset_covid_features.json"))
covid_flat = jsonlite::flatten(COVID_data)
covid_yelp_tbl = as_tibble(covid_flat)
```

This code doesnt actually work.  As you pull in data it is unfortunately in the wrong format a bunch.  I have corrected code down below.  It is still a 
```{r}
combined_tbl = yelp_tbl %>% right_join(covid_yelp_tbl)
covid_yelp_tbl = as.data.frame(covid_yelp_tbl)
# There are only two businesses with the same business id in the two tibbles.
```


```{r}
businesses = data.frame()
index = 5001
# Add in offset to do 5000 daily pulls. Then save to csv file 
for (biz in covid_yelp_tbl$business_id[5001:8600]){
  temp = business_lookup_id(api_key = key, 
                            business_id = biz)
  temp_biz = bind_cols(as.data.frame(t(cbind(temp))), covid_yelp_tbl[index,])
#for (biz in covid_yelp_tbl$business_id[1:10]){
#  temp = business_lookup_id(api_key = key, 
#                            business_id = biz)
    
#  temp = temp[-which(names(temp) %in% c("photos", "photo", 'display_address'))]
#  temp_biz = bind_cols(as.data.frame(bind_cols(temp)[1,]), covid_yelp_tbl[index,])
  #temp_biz = temp_biz[,-which(names(temp_biz) %in% c("photos"))]


  businesses = bind_rows(businesses, temp_biz)
  #print(businesses)
  #index = index + 1
  #if (index %% 100 == 0) {
  #  print(index)
  #}
}
write.csv(businesses, "covid_yelp_biz.csv") 
head(businesses)

```


```{r}
# Feature engineering - highly correlated things turn into one variable, maybe combine # of dollar signs with business rating, to reduce dimensions. Common on interviews. Ratings are variable to the number of rating recieved. 10 ratings will swing a lot while 1000 ratings will swing less with each additional rating. 
# Another option is to get simple sentiment analysis of reviews distilled to a number. 
# Could also add a density mapping based on the city the restaurant is in. Or a score of how strict the city is iwth COVID. 

```

```{r}
businesses = data.frame()
index = 500
# Add in offset to do 5000 daily pulls. Then save to csv file 
for (biz in covid_yelp_tbl$business_id[500:1000]){
  temp = business_lookup_id(api_key = key, 
                            business_id = biz)
  
  #this for loop section goes into bad data entries and removes them
  #too many different options depending on what the category was to make something nicer
  for (i in names(temp)) {
  t = temp[i][[1]]
  if (length(t) > 1 & length(names(t)) > 1) {

    for (j in names(t)) {
      #print(j)
      if (is.vector(t[j]) == T & length(t[j][[1]]) > 1) {
        #print(t[j])
        temp[i][[1]][j][[1]] = NA
      }
    }
  } else if (length(t) > 1) {
      temp = temp[-which(names(temp) %in% c(i))]
    }
  }
  temp_biz = bind_cols(as.data.frame(bind_cols(temp)[1,]), covid_yelp_tbl[index,])

  businesses = bind_rows(businesses, temp_biz)
  index = index + 1
  if (index %% 100 == 0) {
    print(index)
  }
}
```


























