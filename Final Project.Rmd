---
title: "R Notebook"
output: html_notebook
---
Zac Macintyre (Zim2103)
Lukas Geiger (lg2960)	

```{r}
# Load the package required
library("jsonlite")
library(tibble)
library(yelpr)
library(dplyr)
library(stringr)
library(ggplot2)

# Get my API key
key = readLines("Yelp API.txt", warn = F)

# It seems borough by borough is best 
# Manhattan restaurant calls 
resturants = data.frame()
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Manhattan',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Brooklyn restaurant calls 
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Brooklyn',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Queens restaurant calls 
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Queens',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}
#Bronx restaurant calls
for (i in 0:99) {
  
  temp = business_search(api_key = key,
                  location = 'Bronx',
                  term = "resturants",
                  limit = 50,
                  offset = 50*i)
  resturants = bind_rows(resturants, as.data.frame(temp))
}

dim(resturants)
unique(resturants$businesses.location$city)
head(resturants)

cor(resturants$businesses.rating, resturants$businesses.review_count)
```

```{r}
# Initial Yelp API business ids from first iteration 
businesses_test = data.frame()
index = 1
# Add in offset to do 5000 daily pulls. Then save to csv file 
for (biz in covid_yelp_tbl$business_id[1:100]){
  temp = business_lookup_id(api_key = key, 
                            business_id = biz)
  
  for (i in names(temp)) {
  t = temp[i][[1]]
  if (length(t) > 1 & length(names(t)) > 1) {

    for (j in names(t)) {
      #print(j)
      if (is.vector(t[j]) == T & length(t[j][[1]]) > 1) {
        #print(t[j])
        temp[i][[1]][j][[1]] = NA
      }
    }
  } else if (length(t) > 1) {
      temp = temp[-which(names(temp) %in% c(i))]
    }
  }
  temp_biz = bind_cols(as.data.frame(bind_cols(temp)[1,]), covid_yelp_tbl[index,])

  businesses_test = bind_rows(businesses_test, temp_biz)
  index = index + 1
  if (index %% 100 == 0) {
    print(index)
  }
}

head(businesses_test)
```


```{r}
table(resturants$businesses.is_closed, useNA = "ifany")
```

```{r}
hist(resturants$businesses.rating,xlab = "ratings out of 5", main = "Histogram of business ratings")
```

```{r}
table(resturants$businesses.price, useNA = "ifany")
```

```{r}
barplot(height = table(resturants$businesses.price,  useNA = "ifany"), 
        names.arg = names(table(resturants$businesses.price, useNA = "ifany")))
```

```{r}
hist(resturants$businesses.review_count, xlab = "Number of reviews", main = "Histogram of review Dist")
```

Yelp Dataset for Academic purposed as of March 2020

```{r}
# Second iteration - Yelp March 2020 dataset
yelp_biz = jsonlite::stream_in(file( "/Users/lukasgeiger/Desktop/Columbia/SeniorYear/Spring2021/AppliedDataMining/FinalProject/yelp_dataset/yelp_academic_dataset_business.json"))
yelp_flat = jsonlite::flatten(yelp_biz)
yelp_tbl = as_tibble(yelp_flat)
# However, most of this data is from BC, CO, FL, GA, MA, OH, OR, and TX (Not NY)
table(yelp_tbl$state)
# It is a very large dataset
dim(yelp_tbl)
names(yelp_tbl)
#Includes more than restaurants 
yelp_tbl %>% mutate(categories = as.character(categories)) %>% select(categories)
```

```{r}
# Yelp COVID 19 Addendum data
COVID_data = jsonlite::stream_in(file( "/Users/lukasgeiger/Desktop/Columbia/SeniorYear/Spring2021/AppliedDataMining/FinalProject/covid_19_dataset_2020_06_10/yelp_academic_dataset_covid_features.json"))
covid_flat = jsonlite::flatten(COVID_data)
covid_yelp_tbl = as_tibble(covid_flat)
```


```{r}
# Merge Yelp COVID Addendum data with General Yelp API data. Done in batches of 5000 to not break API limit
businesses = data.frame()
index = 1
# Add in offset to do 5000 daily pulls. Then save to csv file 
for (biz in covid_yelp_tbl$business_id[1:5000]){
  temp = business_lookup_id(api_key = key, 
                            business_id = biz)
  temp_biz = bind_cols(as.data.frame(t(cbind(temp))), covid_yelp_tbl[index,])
  businesses = bind_rows(businesses, temp_biz)
  index = index + 1
  #if (index %% 100 == 0) {
  #  print(index)
  #}
}

# check to see if error
tail(businesses$error)
```

```{r}
# Convert DF into an easier format. Right now everything is in a list. 

set_lists_to_chars <- function(x) {
    if(class(x) == 'list') {
    y <- paste(unlist(x[1]), sep='', collapse=', ')
    } else {
    y <- x 
    }
    return(y)
}

nms = names(businesses)
col = c()
for (row in businesses[,1]) {
  col = c(col,set_lists_to_chars(row))
}
bizzes = matrix(ncol=length(nms), nrow=length(col))
colnames(bizzes) = nms
bizzes[,1] = col
for (row in 1:nrow(businesses)){
  for (col in 2:length(businesses)) {
    bizzes[row,col] = set_lists_to_chars(businesses[row,col])
  }
}
nrow(bizzes)
bizzes = as.data.frame(bizzes)
tail(bizzes)

# Append to file so both of us can pull from API at same time
write.table(bizzes, "covid_yelp_biz.csv",append = TRUE,sep = ",") 
```

```{r}
# Data Exploration and cleanup

biz = read.csv("covid_yelp_biz.csv")

# remove all Canandian businesses 
biz = biz[- grep("CA", biz$location),]

# remove all with error not found
biz = biz[- grep("NOT_FOUND", biz$error),]
biz = biz[- grep("BUSINESS_UNAVAILABLE", biz$error),]


biz = biz %>% mutate(price =  na_if(price, ""),
                     photos =  na_if(photos, ""),
                     business_id =  na_if(business_id, ""),
                     highlights =  na_if(highlights, ""),
                     transactions = na_if(transactions, ""),
                     coordinates = na_if(coordinates, ""),
                     location = na_if(location, ""),
                     categories = na_if(categories, ""),
                     display_phone = na_if(display_phone, ""),
                     url = na_if(url, ""),
                     image_url = na_if(image_url, ""),
                     name = na_if(name, ""),
                     alias = na_if(alias, ""),
                     id = na_if(id, ""),
                     hours = na_if(hours, ""),
                     business_id = na_if(business_id, ""),
                     Covid.Banner = na_if(Covid.Banner, ""),
                     Temporary.Closed.Until = na_if(Temporary.Closed.Until, ""),
                     Virtual.Services.Offered = na_if(Virtual.Services.Offered, ""),
                     messaging = na_if(messaging, ""),
                     special_hours = na_if(special_hours, ""))

biz$Virtual.Services.Offered = as.logical(gsub('offers_virtual_consultations|offers_virtual_tours|offers_virtual_classes', 'TRUE', biz$Virtual.Services.Offered))

```

```{r}
# Feature Generation 

# getting covid cases data 
#it was in a weird format with lots of blank spaces 
case = read.csv("covid cases.csv")

covid_cases = data.frame()
for (i in 1:51) {
  row = case[i*4 + 1,1:2]
  covid_cases = bind_rows(covid_cases, row)
}
 
covid_cases$Cases = as.numeric(gsub('\\,', '', covid_cases$Cases)) 

# reading in vaccine data 
vax = read.csv("vaccines.csv")
vaxes = data.frame()
for (i in 1:51) {
  
  c1 = vax[i*2 -1,1]
  c2 = vax[i*2,2:4]
  row = bind_cols(c1,c2)
  vaxes = bind_rows(vaxes, row)
}

names(vaxes) = c("Location", "Doses_given", "Fully_vaccinated", "Population_fully_vaccinated")

vaxes = vaxes %>% mutate(Doses_given = as.numeric(gsub('\\,', '', Doses_given)),
                         Fully_vaccinated = as.numeric(gsub('\\,', '', Fully_vaccinated)),
                         Population_fully_vaccinated = as.numeric(gsub('\\%', '',
                                                                       Population_fully_vaccinated)))

#merging into 1 DF
covid = merge(vaxes, covid_cases, by = "Location")

```

```{r}
#feature creation section 
covid$Population_fully_vaccinated = covid$Population_fully_vaccinated / 100
covid$feature = covid$Cases * (1 - covid$Population_fully_vaccinated) 

#scaling the feature between 0 and 1 
covid$scaled_feature = (covid$feature - min(covid$feature)) / (max(covid$feature) - min(covid$feature))

```

```{r}
# Matching country and State codes so we can merge on state

pattern = "[[:upper:]]{2},"

biz = biz %>% rowwise() %>% mutate(Code = str_remove(paste(
  unique(
  str_sub(unlist(str_extract_all(location,pattern)), 
          end = -2)
  ), collapse=" "), pattern = "US"))


# Get state Codes
state_abrev = read.csv("state_abbrev.csv")
state_abrev = state_abrev %>% mutate(Location = State) %>% select("Location", "Code") 
covid = merge(covid, state_abrev, by = "Location")

# Merge (biz would not merge on State code because not equal number of rows so we did it using for loop)
cobiz = data.frame()
for (i in 1:nrow(biz)) {
  if (!is.na(biz[i,"id"]) & 
      length(str_split(biz[i,"Code"], , pattern = "  ")[[1]]) == 1 & 
      biz[i,"Code"]!="NA") 
    {
    row = cbind(biz[i,], 
                covid[which(covid$Code == str_trim(unlist(biz[i,"Code"]))),]) %>%
      select(!Code)
    cobiz = bind_rows(cobiz, row)
  }
}
biz = cobiz
biz = cobiz[1:3600,]
```

```{r}
# Data cleanup 
biz = biz %>% rowwise() %>% mutate(delivery.or.takeout = ifelse(delivery.or.takeout == "TRUE" | delivery.or.takeout == "FALSE", delivery.or.takeout, NA))

biz = biz %>% rowwise() %>% mutate(Grubhub.enabled = ifelse(Grubhub.enabled == "TRUE" | Grubhub.enabled == "FALSE", Grubhub.enabled, NA))
```

```{r}
table(biz$is_closed , useNA = "ifany")
# This is actually pretty good for us so far, we dont have crazy disproportionate classes 
```


```{r}

barplot(height = table(biz$rating,  useNA = "ifany"), 
        names.arg = names(table(biz$rating, useNA = "ifany")), xlab = "rating of the biz")

barplot(height = table(biz$price,  useNA = "ifany"), 
        names.arg = names(table(biz$price, useNA = "ifany")), xlab = "prices of the biz")

ggplot(biz, aes(x = rating, group = is_closed, fill = is_closed)) + geom_histogram(position="dodge",binwidth=0.25)+theme_bw() + labs(title = "Histogram Business Rating by Open/Closed")

table(biz$is_closed)

ggplot(data = biz[biz$review_count < 100,]) +
  geom_histogram(mapping = aes(x = review_count), fill = "dodgerblue2") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = "Histogram of Review counts < 100")

ggplot(data = biz[biz$review_count > 100,]) +
  geom_histogram(mapping = aes(x = review_count), fill = "dodgerblue2") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = "Histogram of Review counts > 100")

```

```{r}
# all the NAs in each col
colSums(is.na(biz[,1:30]))

#total missing values 
percent_missing = sum(colSums(is.na(biz[,1:29]))) / (8177 *30)
percent_missing

```



```{r}
#wrote this so you didnt have to change the actual DF
#probably makes sense to do so and did it after
prices = rep(NA, length(biz$price))
length(prices)

for (i in 1:length(biz$price)) {
  if (!is.na(biz$price[i]) & biz$price[i] == '$') {
    prices[i] = 1
  } else if (!is.na(biz$price[i]) & biz$price[i] == '$$') {
      prices[i] = 2
  } else if (!is.na(biz$price[i]) & biz$price[i] == '$$$') {
      prices[i] = 3
  } else if (!is.na(biz$price[i]) & biz$price[i] == '$$$$') {
      prices[i] = 4
  }
}

```

```{r}
biz$price = prices 
```

```{r}
#geting some of the cor for things that are numeric
cor(biz$rating, prices, use = "pairwise.complete.obs")
cor(biz$rating, biz$review_count, use = "pairwise.complete.obs")
cor(biz$price, biz$review_count, use = "pairwise.complete.obs")
```

```{r}
#geting some of the cor for things that are numeric
#specifically looking at it with is the business closed
cor(biz$is_closed, biz$price, use = "pairwise.complete.obs")
cor(biz$is_closed, biz$review_count, use = "pairwise.complete.obs")
cor(biz$is_closed, biz$rating, use = "pairwise.complete.obs")
```


```{r}
# Get data ready for Model
# running a logistic regression on the data that has numeric or boolean values 
y = biz$is_closed
x1 = biz$review_count
x2 = biz$rating
x3 = biz$price
x4 = biz$delivery.or.takeout 
x5 = biz$Grubhub.enabled
x6 = biz$Virtual.Services.Offered
x7 = biz$Population_fully_vaccinated
x7 = biz$scaled_feature

X = as.data.frame(cbind(y, x1,x2,x3,x4,x5,x6,x7))
X = X %>% mutate(x1 = as.numeric(x1),
                 x2 = as.numeric(x2),
                 x3 = as.numeric(x3),
                 x4 = as.logical(x4),
                 x5 = as.logical(x5),
                 x6 = as.logical(x6),
                 x7 = as.numeric(x7),
                 y = as.logical(y))

#correlation of everything together
cor(X, use = "pairwise.complete.obs")
```


```{r}
# Train the model

train <- sample(c(TRUE, FALSE), nrow(biz), replace=TRUE)
mod <- glm(y ~ x1+x2+x3+x4+x5+x6+x7, family=binomial(link="logit"),
           subset=train)
test = data.frame(x1,x2,x3,x4,x5,x6,x7)[!train,]
test_probs <- predict(mod, newdata=data.frame(x=test), type="response")

idx = sample(1:nrow(X), (nrow(X) * .8), replace = F)
train = X[idx,]

test = X[-idx,1:6]
mod <- glm(y ~ ., data = train, family=binomial(link="logit"))
summary(mod)

# predictions from the model 
test_probs <- predict(mod, newdata= test, type="response")
test_pred = test_probs > .5
correct = X[-idx, 7]


test_pred[1:10]
correct[1:10]
score = 0
na = 0

for (i in 1:length(correct)) {
  
  if (is.na(test_pred[i])) {
    na = na + 1
    
  } else if (!is.na(test_pred) & (test_pred[i] == correct[i])) {
  score = score + 1
  }
}

score
na
```

```{r}
# Tuning Model
#removing highly corelated variables
y = biz$is_closed
x1 = biz$review_count
x2 = biz$rating
x3 = biz$price
x5 = biz$Grubhub.enabled
x6 = biz$Virtual.Services.Offered
x7 = biz$scaled_feature

X = as.data.frame(cbind(y, x1,x2,x3,x5,x6,x7))
X = X %>% mutate(x1 = as.numeric(x1),
                 x2 = as.numeric(x2),
                 x3 = as.numeric(x3),
                 x5 = as.logical(x5),
                 x6 = as.logical(x6),
                 x7 = as.numeric(x7),
                 y = as.logical(y))

#correlation of everything together
cor(X, use = "pairwise.complete.obs")
```


```{r}
# Train tuned model
idx = sample(1:nrow(X), (nrow(X) * .8), replace = F)
train = X[idx,]

test = X[-idx,1:6]
mod <- glm(y ~ ., data = train, family=binomial(link="logit"))
summary(mod)
```


```{r}
signif = list( review_count = 4, rating = 0, price = 5, grubhub = 5, virtual = 0 , feature = 5)

barplot(height = unlist(signif), main = "Times Significant")
```


```{r}
# predictions from the model 
test_probs <- predict(mod, newdata= test, type="response")
test_pred = test_probs > .5
correct = X[-idx, 7]


test_pred[1:10]
correct[1:10]
score = 0
na = 0

for (i in 1:length(correct)) {
  
  if (is.na(test_pred[i])) {
    na = na + 1
    
  } else if (!is.na(test_pred) & (test_pred[i] == correct[i])) {
  score = score + 1
  }
}

score
na
```


```{r}
# A further look on business reviews 

#looking at the hold reviews above 200
X_review = X[X$x1 > 200,]

dim(X_review)
#i am goiing to have to maybe make a new way to test/train split for evaluation
#but it works for the moment
#train <- sample(c(TRUE, FALSE), nrow(biz), replace=TRUE)
idx = sample(1:nrow(X_review), (nrow(X_review) * .8), replace = F)
train = X_review[idx,]

test = X_review[-idx,1:6]
mod <- glm(y ~ ., data = train, family=binomial(link="logit"))
summary(mod)
```






